{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mikle\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\Mikle\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\Mikle\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import PIL\n",
    "import PIL.Image\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 28\n",
    "img_width = 28\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26179 files belonging to 10 classes.\n",
      "Using 18326 files for training.\n",
      "Found 26179 files belonging to 10 classes.\n",
      "Using 7853 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# path = \"/Users/Mikle/Downloads/dataSubfolders\"\n",
    "path = r\"C:\\Users\\Mikle\\Downloads\\dataSubfolders\\raw-img\"\n",
    "\n",
    "train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    path,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    class_names=['squirrel','spider','lamb','cow','cat','chicken','butterfly','elephant','horse','dog'],\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.3,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "test = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    path,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    class_names=['squirrel','spider','lamb','cow','cat','chicken','butterfly','elephant','horse','dog'],\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.3,\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: '<_BatchDataset element_spec=(TensorSpec(shape=(None, 28, 28, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m----> 2\u001b[0m data \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39;49mimread(\u001b[39mstr\u001b[39;49m(train))\n\u001b[0;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloadImgs\u001b[39m(train):\n\u001b[0;32m      5\u001b[0m     \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m path:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\matplotlib\\image.py:1563\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fname, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(parse\u001b[39m.\u001b[39murlparse(fname)\u001b[39m.\u001b[39mscheme) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1557\u001b[0m     \u001b[39m# Pillow doesn't handle URLs directly.\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1559\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease open the URL for reading and pass the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1560\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mresult to Pillow, e.g. with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1561\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1562\u001b[0m         )\n\u001b[1;32m-> 1563\u001b[0m \u001b[39mwith\u001b[39;00m img_open(fname) \u001b[39mas\u001b[39;00m image:\n\u001b[0;32m   1564\u001b[0m     \u001b[39mreturn\u001b[39;00m (_pil_png_to_float_array(image)\n\u001b[0;32m   1565\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(image, PIL\u001b[39m.\u001b[39mPngImagePlugin\u001b[39m.\u001b[39mPngImageFile) \u001b[39melse\u001b[39;00m\n\u001b[0;32m   1566\u001b[0m             pil_to_array(image))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\PIL\\Image.py:3227\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3224\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[0;32m   3226\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[1;32m-> 3227\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   3228\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   3230\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: '<_BatchDataset element_spec=(TensorSpec(shape=(None, 28, 28, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf421da685e731a47b20a3ccf7e052eb55e76ab3ec78ec8cd407d78ef802f6a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
